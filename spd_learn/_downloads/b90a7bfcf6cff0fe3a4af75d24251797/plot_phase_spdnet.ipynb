{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SPD Learn Example\n",
    "# ==================\n",
    "#\n",
    "# First, install the required packages:\n",
    "\n",
    "!uv pip install -q spd_learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n\n# Phase-Space Embedding with PhaseSPDNet\n\nThis tutorial demonstrates how to use PhaseSPDNet for EEG classification.\nPhaseSPDNet applies phase-space embedding (time-delay coordinates) to\ncapture nonlinear dynamical structure before SPDNet processing.\n   :depth: 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n\nPhaseSPDNet :cite:p:`carrara2024eegspd` leverages **phase-space embedding**\nfrom dynamical\nsystems theory. The key idea is that a single time series can be\n\"unfolded\" into a higher-dimensional space that reveals the underlying\ndynamics of the system.\n\n**Takens' Embedding Theorem**: For a dynamical system, a time-delayed\nembedding can reconstruct the topology of the original state space:\n\n\\begin{align}\\mathbf{x}(t) \\rightarrow [\\mathbf{x}(t), \\mathbf{x}(t-\\tau), \\mathbf{x}(t-2\\tau), \\ldots]\\end{align}\n\nThis is particularly useful for EEG, where signals reflect complex\nbrain dynamics that may not be fully captured by linear methods.\n\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from braindecode import EEGClassifier\n",
    "from moabb.datasets import BNCI2014_001\n",
    "from moabb.paradigms import MotorImagery\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skorch.callbacks import EpochScoring, GradientNormClipping\n",
    "from skorch.dataset import ValidSplit\n",
    "\n",
    "from spd_learn.models import PhaseSPDNet\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = BNCI2014_001()\n",
    "paradigm = MotorImagery(n_classes=4)\n",
    "\n",
    "print(f\"Dataset: {dataset.code}\")\n",
    "print(\"Sampling rate: 250 Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Phase-Space Embedding\n\nFor a signal with ``n_chans`` channels, phase-space embedding with\n``order=m`` and ``lag=τ`` creates:\n\n\\begin{align}X_{embedded}(t) = [X(t), X(t-\\tau), X(t-2\\tau), \\ldots, X(t-(m-1)\\tau)]\\end{align}\n\nThis increases the channel dimension by a factor of ``m``:\n``n_chans → n_chans * order``\n\n**Choosing parameters**:\n\n- ``order``: Embedding dimension (typically 2-5)\n- ``lag``: Time delay in samples (often chosen via autocorrelation)\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize embedding concept\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Original 1D signal\n",
    "t = np.linspace(0, 4 * np.pi, 200)\n",
    "x = np.sin(t) + 0.5 * np.sin(2 * t)\n",
    "\n",
    "ax1 = axes[0]\n",
    "ax1.plot(t, x, \"b-\", linewidth=2)\n",
    "ax1.set_xlabel(\"Time\", fontsize=12)\n",
    "ax1.set_ylabel(\"Amplitude\", fontsize=12)\n",
    "ax1.set_title(\"Original Signal\", fontsize=14)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Phase-space embedding (2D)\n",
    "lag = 15  # samples\n",
    "x_delayed = x[:-lag]\n",
    "x_original = x[lag:]\n",
    "\n",
    "ax2 = axes[1]\n",
    "ax2.plot(x_original, x_delayed, \"b-\", linewidth=1, alpha=0.7)\n",
    "ax2.scatter(x_original[::10], x_delayed[::10], c=t[lag::10], cmap=\"viridis\", s=30)\n",
    "ax2.set_xlabel(\"x(t)\", fontsize=12)\n",
    "ax2.set_ylabel(\"x(t - τ)\", fontsize=12)\n",
    "ax2.set_title(\"Phase-Space Embedding (2D)\", fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_aspect(\"equal\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Phase-space embedding reveals the underlying attractor structure!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the PhaseSPDNet Model\n\nPhaseSPDNet architecture:\n\n1. **PhaseDelay**: Applies time-delay embedding\n2. **SPDNet**: Processes the embedded signals\n\nThe embedding expands channels: 22 channels x order 3 = 66 channels\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_chans = 22\n",
    "n_outputs = 4\n",
    "\n",
    "# Phase-space parameters\n",
    "order = 2  # Embedding dimension (lower for stability)\n",
    "lag = 10  # Time delay (~40ms at 250Hz)\n",
    "\n",
    "model = PhaseSPDNet(\n",
    "    n_chans=n_chans,\n",
    "    n_outputs=n_outputs,\n",
    "    order=order,\n",
    "    lag=lag,\n",
    "    subspacedim=22,  # BiMap output dimension (half of embedded channels)\n",
    "    threshold=1e-4,\n",
    ")\n",
    "\n",
    "print(\"PhaseSPDNet Configuration:\")\n",
    "print(f\"  Original channels: {n_chans}\")\n",
    "print(f\"  Embedding order: {order}\")\n",
    "print(f\"  Time lag: {lag} samples ({lag/250*1000:.1f} ms)\")\n",
    "print(f\"  Embedded channels: {n_chans * order}\")\n",
    "print(\"  Subspace dimension: 22\")\n",
    "print(\"\\nModel Architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subject_id = 1\n",
    "batch_size = 32\n",
    "max_epochs = 100\n",
    "learning_rate = 1e-4  # Low learning rate for stable SPD learning\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "# Cache configuration\n",
    "cache_config = dict(\n",
    "    save_raw=True,\n",
    "    save_epochs=True,\n",
    "    save_array=True,\n",
    "    use=True,\n",
    "    overwrite_raw=False,\n",
    "    overwrite_epochs=False,\n",
    "    overwrite_array=False,\n",
    ")\n",
    "\n",
    "# Load data\n",
    "X, labels, meta = paradigm.get_data(\n",
    "    dataset=dataset, subjects=[subject_id], cache_config=cache_config\n",
    ")\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)\n",
    "\n",
    "# Split by session\n",
    "train_idx = meta.query(\"session == '0train'\").index.to_numpy()\n",
    "test_idx = meta.query(\"session == '1test'\").index.to_numpy()\n",
    "\n",
    "print(f\"\\nData shape: {X.shape}\")\n",
    "print(\n",
    "    f\"After embedding: ({X.shape[0]}, {n_chans * order}, {X.shape[2] - (order-1)*lag})\"\n",
    ")\n",
    "print(f\"Training samples: {len(train_idx)}\")\n",
    "print(f\"Test samples: {len(test_idx)}\")\n",
    "\n",
    "# Create classifier\n",
    "# Note: SPD networks benefit from gradient clipping to prevent\n",
    "# divergence during training on the Riemannian manifold.\n",
    "clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    optimizer__lr=learning_rate,\n",
    "    train_split=ValidSplit(0.1, stratified=True, random_state=42),\n",
    "    batch_size=batch_size,\n",
    "    max_epochs=max_epochs,\n",
    "    callbacks=[\n",
    "        (\n",
    "            \"train_acc\",\n",
    "            EpochScoring(\n",
    "                \"accuracy\", lower_is_better=False, on_train=True, name=\"train_acc\"\n",
    "            ),\n",
    "        ),\n",
    "        (\"gradient_clip\", GradientNormClipping(gradient_clip_value=1.0)),\n",
    "    ],\n",
    "    device=device,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Train\n",
    "clf.fit(X[train_idx], y[train_idx])\n",
    "\n",
    "# Evaluate\n",
    "y_pred_train = clf.predict(X[train_idx])\n",
    "y_pred_test = clf.predict(X[test_idx])\n",
    "\n",
    "train_acc = accuracy_score(y[train_idx], y_pred_train)\n",
    "test_acc = accuracy_score(y[test_idx], y_pred_test)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Results for Subject {subject_id}\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Train Accuracy: {train_acc*100:.2f}%\")\n",
    "print(f\"Test Accuracy:  {test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Results\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Training curves\n",
    "history = clf.history\n",
    "epochs = range(1, len(history) + 1)\n",
    "\n",
    "ax1 = axes[0]\n",
    "ax1.plot(epochs, history[:, \"train_loss\"], \"b-\", label=\"Train Loss\", linewidth=2)\n",
    "ax1.plot(epochs, history[:, \"valid_loss\"], \"r--\", label=\"Valid Loss\", linewidth=2)\n",
    "ax1.set_xlabel(\"Epoch\", fontsize=12)\n",
    "ax1.set_ylabel(\"Loss\", fontsize=12)\n",
    "ax1.set_title(\"Training and Validation Loss\", fontsize=14)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2 = axes[1]\n",
    "ax2.plot(epochs, history[:, \"train_acc\"], \"b-\", label=\"Train Acc\", linewidth=2)\n",
    "ax2.plot(epochs, history[:, \"valid_acc\"], \"r--\", label=\"Valid Acc\", linewidth=2)\n",
    "ax2.set_xlabel(\"Epoch\", fontsize=12)\n",
    "ax2.set_ylabel(\"Accuracy\", fontsize=12)\n",
    "ax2.set_title(\"Training and Validation Accuracy\", fontsize=14)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim([0, 1])\n",
    "\n",
    "# Confusion matrix\n",
    "ax3 = axes[2]\n",
    "cm = confusion_matrix(y[test_idx], y_pred_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(ax=ax3, cmap=\"Blues\", values_format=\"d\")\n",
    "ax3.set_title(f\"Confusion Matrix\\nAccuracy: {test_acc*100:.1f}%\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Different Embedding Parameters\n\nThe choice of ``order`` and ``lag`` affects performance.\nLet's compare different configurations.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\nComparing embedding parameters:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "configs = [\n",
    "    {\"order\": 2, \"lag\": 5, \"name\": \"order=2, lag=5\"},\n",
    "    {\"order\": 2, \"lag\": 10, \"name\": \"order=2, lag=10\"},\n",
    "    {\"order\": 3, \"lag\": 5, \"name\": \"order=3, lag=5\"},\n",
    "    {\"order\": 3, \"lag\": 10, \"name\": \"order=3, lag=10\"},\n",
    "]\n",
    "\n",
    "for config in configs:\n",
    "    embedded_chans = n_chans * config[\"order\"]\n",
    "    reduced_time = X.shape[2] - (config[\"order\"] - 1) * config[\"lag\"]\n",
    "    cov_size = embedded_chans * (embedded_chans + 1) // 2\n",
    "    print(\n",
    "        f\"{config['name']:20s}: {embedded_chans} channels, \"\n",
    "        f\"{reduced_time} time points, {cov_size} features\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to Use Phase-Space Embedding\n\nPhaseSPDNet is particularly effective when:\n\n1. **Nonlinear dynamics**: The underlying system has complex,\n   nonlinear behavior (e.g., neural oscillations, chaos)\n\n2. **Limited channels**: Embedding can extract more information\n   from fewer channels\n\n3. **Temporal structure**: Important features span across time\n   (captured by delay coordinates)\n\n**Considerations**:\n\n- Higher ``order`` increases model capacity but also parameters\n- ``lag`` should be chosen based on the signal's autocorrelation\n- Reduces effective time dimension: ``T_new = T - (order-1) * lag``\n\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n\nIn this tutorial, we demonstrated:\n\n1. Phase-space embedding theory and visualization\n2. Creating PhaseSPDNet with different embedding parameters\n3. Training and evaluating on motor imagery data\n\nPhaseSPDNet offers a principled way to incorporate dynamical\nsystems perspectives into EEG classification, potentially\ncapturing nonlinear brain dynamics that linear methods miss.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.close(\"all\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
