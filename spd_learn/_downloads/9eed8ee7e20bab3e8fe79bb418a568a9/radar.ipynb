{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SPD Learn Example\n",
    "# ==================\n",
    "#\n",
    "# First, install the required packages:\n",
    "\n",
    "!uv pip install -q spd_learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n\n# Radar Image Classification with SPD Learn\n\nThis tutorial demonstrates how to use **spd_learn** for synthetic aperture\nradar (SAR) polarimetric image classification using **real UAVSAR data**.\nPolarimetric SAR data naturally produces symmetric positive definite (SPD)\ncovariance matrices, making this an ideal application for SPD-based\nmachine learning.\n\nWe use the UAVSAR dataset from NASA's Uninhabited Aerial Vehicle Synthetic\nAperture Radar system, with pseudo-labels generated via Riemannian clustering.\n   :depth: 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n\nPolarimetric SAR (PolSAR) :cite:p:`lee2009polarimetric` systems transmit and\nreceive electromagnetic waves in multiple polarization states (typically\nHH, HV, VH, VV), capturing rich information about the scattering properties\nof terrain and objects.\n\nThe data is commonly represented as coherency or covariance matrices,\nwhich are **inherently SPD matrices**. This makes SPD-based deep learning\napproaches particularly well-suited for PolSAR classification tasks.\n\n**The UAVSAR Dataset**\n\nThe UAVSAR (Uninhabited Aerial Vehicle Synthetic Aperture Radar) is a\nNASA/JPL airborne SAR system. The data used here covers the Los Angeles\narea with:\n\n- **Source**: NASA/JPL UAVSAR, L-band\n- **Format**: Polarimetric scattering vectors (3 channels: HH, HV, VV)\n- **Hosted on**: Zenodo (open access)\n\nIn this tutorial, we:\n\n1. Load real UAVSAR PolSAR data\n2. Visualize the radar image using Pauli RGB decomposition\n   :cite:p:`cloude1996review`\n3. Generate pseudo-labels using Riemannian K-Means clustering\n4. Train SPDNet :cite:p:`huang2017riemannian` and compare with pyRiemann\n   baselines\n\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "from pathlib import Path\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from braindecode import EEGClassifier\n",
    "from numpy.typing import NDArray\n",
    "from pyriemann.classification import MDM\n",
    "from pyriemann.clustering import Kmeans\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from skorch.callbacks import EarlyStopping, EpochScoring\n",
    "from skorch.dataset import ValidSplit\n",
    "\n",
    "from spd_learn.models import SPDNet\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UAVSAR Data Loading\n\nThe UAVSAR dataset is hosted on Zenodo and contains processed PolSAR\nscattering vectors from the Los Angeles area.\n\nData source: https://zenodo.org/records/10625505\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data_dir() -> Path:\n",
    "    \"\"\"Get the data directory for storing downloaded datasets.\"\"\"\n",
    "    data_dir = Path.home() / \".spd_learn_data\" / \"uavsar\"\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    return data_dir\n",
    "\n",
    "\n",
    "def verify_npy_file(filepath: Path, expected_shape: tuple = (2360, 600, 3, 4)) -> bool:\n",
    "    \"\"\"Verify that a .npy file is complete and valid.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : Path\n",
    "        Path to the .npy file.\n",
    "    expected_shape : tuple\n",
    "        Expected shape of the array.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if file is valid, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = np.load(filepath)\n",
    "        if data.shape != expected_shape:\n",
    "            logger.warning(f\"Unexpected shape: {data.shape} vs {expected_shape}\")\n",
    "            return False\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"File verification failed: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def download_uavsar(data_path: Path, scene: int = 1) -> Path:\n",
    "    \"\"\"Download the UAVSAR dataset from Zenodo.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_path : Path\n",
    "        Path to the destination folder for data download.\n",
    "    scene : {1, 2}\n",
    "        Scene index to download.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Path\n",
    "        Path to the downloaded file.\n",
    "    \"\"\"\n",
    "    assert scene in [1, 2], f\"Unknown scene {scene} for UAVSAR dataset\"\n",
    "    filename = f\"scene{scene}.npy\"\n",
    "    src = f\"https://zenodo.org/records/10625505/files/{filename}?download=1\"\n",
    "\n",
    "    if not data_path.exists():\n",
    "        data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    dst = data_path / filename\n",
    "\n",
    "    # Check if file exists and is valid\n",
    "    if dst.exists():\n",
    "        logger.info(f\"Verifying existing file: {dst}\")\n",
    "        if verify_npy_file(dst):\n",
    "            logger.info(\"File verified successfully!\")\n",
    "            return dst\n",
    "        else:\n",
    "            logger.warning(\"File corrupted or incomplete. Re-downloading...\")\n",
    "            dst.unlink()  # Remove corrupted file\n",
    "\n",
    "    logger.info(f\"Downloading UAVSAR scene {scene} from Zenodo...\")\n",
    "    logger.info(f\"Source: {src}\")\n",
    "    logger.info(f\"Destination: {dst}\")\n",
    "    logger.info(\"This may take a few minutes for the ~136MB file...\")\n",
    "    urlretrieve(src, dst)\n",
    "\n",
    "    # Verify the downloaded file\n",
    "    if not verify_npy_file(dst):\n",
    "        raise RuntimeError(\n",
    "            \"Downloaded file is corrupted. Please try again or \"\n",
    "            \"manually download from: https://zenodo.org/records/10625505\"\n",
    "        )\n",
    "\n",
    "    logger.info(\"Download complete and verified!\")\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n\nWe load the UAVSAR data which contains polarimetric scattering vectors.\nThe data has shape (height, width, 3, n_dates) where the 3 channels\ncorrespond to [HH, HV, VV] polarizations.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Loading Real UAVSAR PolSAR Data\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "data_path = get_data_dir()\n",
    "file_path = download_uavsar(data_path, scene=1)\n",
    "\n",
    "# Load the data\n",
    "data = np.load(file_path)\n",
    "print(f\"Original data shape: {data.shape}\")\n",
    "# Shape: (height, width, 3, n_dates)\n",
    "\n",
    "# Select first date\n",
    "date_idx = 0\n",
    "data = data[:, :, :, date_idx]\n",
    "print(f\"After date selection: {data.shape}\")\n",
    "\n",
    "# Store original dimensions for visualization\n",
    "h_orig, w_orig, n_channels = data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the SAR Image\n\nWe visualize the radar image using standard SAR representations:\n\n1. **Total Power (Span)**: Sum of all polarimetric powers\n2. **Pauli RGB**: Color composite showing scattering mechanisms\n\n   - Red: ``abs(HH - VV)`` (double-bounce)\n   - Green: ``abs(HV)`` (volume scattering)\n   - Blue: ``abs(HH + VV)`` (surface scattering)\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute intensity image (in dB)\n",
    "intensity = 20 * np.log10(np.sum(np.abs(data) ** 2, axis=2) + 1e-10)\n",
    "\n",
    "# Compute Pauli RGB components\n",
    "HH = data[:, :, 0]\n",
    "HV = data[:, :, 1]\n",
    "VV = data[:, :, 2]\n",
    "\n",
    "# Pauli decomposition\n",
    "pauli_red = np.abs(HH - VV)  # Double-bounce\n",
    "pauli_green = np.abs(HV) * np.sqrt(2)  # Volume\n",
    "pauli_blue = np.abs(HH + VV)  # Surface\n",
    "\n",
    "\n",
    "def normalize_for_display(img: NDArray, percentile: tuple = (2, 98)) -> NDArray:\n",
    "    \"\"\"Normalize image for display with percentile clipping.\"\"\"\n",
    "    p_low, p_high = np.percentile(img, percentile)\n",
    "    img_norm = (img - p_low) / (p_high - p_low + 1e-10)\n",
    "    return np.clip(img_norm, 0, 1)\n",
    "\n",
    "\n",
    "# Create Pauli RGB image\n",
    "pauli_rgb = np.stack(\n",
    "    [\n",
    "        normalize_for_display(pauli_red),\n",
    "        normalize_for_display(pauli_green),\n",
    "        normalize_for_display(pauli_blue),\n",
    "    ],\n",
    "    axis=2,\n",
    ")\n",
    "\n",
    "# Create figure with SAR visualizations\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Total power (Span)\n",
    "ax = axes[0]\n",
    "im = ax.imshow(intensity, cmap=\"gray\", aspect=\"auto\")\n",
    "ax.set_title(\"SAR Intensity (dB)\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Range\")\n",
    "ax.set_ylabel(\"Azimuth\")\n",
    "plt.colorbar(im, ax=ax, label=\"dB\")\n",
    "\n",
    "# Pauli RGB\n",
    "ax = axes[1]\n",
    "ax.imshow(pauli_rgb, aspect=\"auto\")\n",
    "ax.set_title(\"Pauli RGB Decomposition\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Range\")\n",
    "ax.set_ylabel(\"Azimuth\")\n",
    "\n",
    "# Add legend for Pauli colors\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "\n",
    "legend_elements = [\n",
    "    Patch(facecolor=\"red\", label=\"Double-bounce |HH-VV|\"),\n",
    "    Patch(facecolor=\"green\", label=\"Volume |HV|\"),\n",
    "    Patch(facecolor=\"blue\", label=\"Surface |HH+VV|\"),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc=\"upper right\", fontsize=8)\n",
    "\n",
    "# Individual channels\n",
    "ax = axes[2]\n",
    "ax.imshow(normalize_for_display(np.abs(HV)), cmap=\"viridis\", aspect=\"auto\")\n",
    "ax.set_title(\"Cross-pol |HV| (Volume Scattering)\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Range\")\n",
    "ax.set_ylabel(\"Azimuth\")\n",
    "\n",
    "plt.suptitle(\n",
    "    \"UAVSAR Los Angeles - Polarimetric SAR Visualization\",\n",
    "    fontsize=14,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Covariance Matrices\n\nFor SPD-based classification, we compute local covariance matrices\nusing a sliding window approach. Each pixel gets a 3x3 covariance\nmatrix estimated from its neighborhood.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Computing Covariance Matrices\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Downsample for computational efficiency\n",
    "downsample_h = 7\n",
    "downsample_w = 4\n",
    "data_ds = data[::downsample_h, ::downsample_w, :]\n",
    "h_ds, w_ds, _ = data_ds.shape\n",
    "print(f\"Downsampled shape: {data_ds.shape}\")\n",
    "\n",
    "# Reshape for covariance estimation\n",
    "# We'll compute covariance from the scattering vector at each pixel\n",
    "# Shape: (n_pixels, n_channels)\n",
    "data_flat = data_ds.reshape(-1, n_channels)\n",
    "n_pixels = data_flat.shape[0]\n",
    "print(f\"Number of pixels: {n_pixels}\")\n",
    "\n",
    "# Compute covariance matrices from scattering vectors\n",
    "# C = k * k^H where k = [HH, HV, VV]\n",
    "print(\"Computing covariance matrices...\")\n",
    "covs = np.zeros((n_pixels, 3, 3), dtype=np.float64)\n",
    "\n",
    "for i in range(n_pixels):\n",
    "    k = data_flat[i]  # Scattering vector\n",
    "    C = np.outer(k, np.conj(k))  # Outer product\n",
    "    covs[i] = np.real(C)  # Take real part\n",
    "\n",
    "# Ensure strong positive definiteness for Riemannian operations\n",
    "# Riemannian mean computation requires well-conditioned matrices\n",
    "print(\"Ensuring positive definiteness...\")\n",
    "min_eigenvalue = 1e-4  # Minimum eigenvalue for numerical stability\n",
    "for i in range(n_pixels):\n",
    "    # Symmetrize\n",
    "    covs[i] = (covs[i] + covs[i].T) / 2\n",
    "    # Compute eigenvalues\n",
    "    eigvals = np.linalg.eigvalsh(covs[i])\n",
    "    # Add regularization to ensure minimum eigenvalue\n",
    "    if np.min(eigvals) < min_eigenvalue:\n",
    "        covs[i] += (min_eigenvalue - np.min(eigvals) + 1e-6) * np.eye(3)\n",
    "\n",
    "X = covs\n",
    "print(f\"Covariance matrices shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering for Pseudo-Labels\n\nSince UAVSAR doesn't have ground truth labels, we use Riemannian\nK-Means clustering to segment the image into terrain types.\nThe clusters serve as pseudo-labels for classification.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Riemannian K-Means Clustering\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "n_clusters = 3  # Reduced from 5 for faster documentation build\n",
    "\n",
    "print(f\"Clustering into {n_clusters} classes using Riemannian K-Means...\")\n",
    "kmeans = Kmeans(n_clusters=n_clusters, metric=\"riemann\", random_state=SEED)\n",
    "y = kmeans.fit_predict(X)\n",
    "\n",
    "# Reshape labels back to image\n",
    "labels_image = y.reshape(h_ds, w_ds)\n",
    "\n",
    "# Count samples per cluster\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(\"\\nCluster distribution:\")\n",
    "for cluster, count in zip(unique, counts):\n",
    "    print(f\"  Cluster {cluster}: {count} pixels ({count/len(y)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Clustering Results\n\nWe display the clustering results as a segmentation map overlaid\non the original SAR image, similar to pyRiemann's visualization.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Downsample Pauli RGB for comparison\n",
    "pauli_rgb_ds = pauli_rgb[::downsample_h, ::downsample_w, :]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Original Pauli RGB (downsampled)\n",
    "ax = axes[0]\n",
    "ax.imshow(pauli_rgb_ds, aspect=\"auto\")\n",
    "ax.set_title(\"Pauli RGB (Downsampled)\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Range\")\n",
    "ax.set_ylabel(\"Azimuth\")\n",
    "\n",
    "# Clustering result\n",
    "ax = axes[1]\n",
    "im = ax.imshow(labels_image, cmap=\"tab10\", aspect=\"auto\")\n",
    "ax.set_title(\n",
    "    f\"Riemannian K-Means ({n_clusters} clusters)\", fontsize=12, fontweight=\"bold\"\n",
    ")\n",
    "ax.set_xlabel(\"Range\")\n",
    "ax.set_ylabel(\"Azimuth\")\n",
    "plt.colorbar(im, ax=ax, label=\"Cluster\")\n",
    "\n",
    "# Overlay: Pauli RGB with cluster boundaries\n",
    "ax = axes[2]\n",
    "ax.imshow(pauli_rgb_ds, aspect=\"auto\")\n",
    "ax.contour(\n",
    "    labels_image, levels=n_clusters - 1, colors=\"white\", linewidths=0.5, alpha=0.7\n",
    ")\n",
    "ax.set_title(\"Pauli RGB with Cluster Boundaries\", fontsize=12, fontweight=\"bold\")\n",
    "ax.set_xlabel(\"Range\")\n",
    "ax.set_ylabel(\"Azimuth\")\n",
    "\n",
    "plt.suptitle(\"UAVSAR Segmentation Results\", fontsize=14, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Cluster Characteristics\n\nLet's examine the covariance structure of each cluster to understand\nwhat terrain types they might represent.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, n_clusters, figsize=(3 * n_clusters, 6))\n",
    "\n",
    "for cluster_idx in range(n_clusters):\n",
    "    # Get samples from this cluster\n",
    "    mask = y == cluster_idx\n",
    "    cluster_covs = X[mask]\n",
    "\n",
    "    # Mean covariance matrix\n",
    "    mean_cov = np.mean(cluster_covs, axis=0)\n",
    "\n",
    "    # Plot mean covariance\n",
    "    ax = axes[0, cluster_idx]\n",
    "    im = ax.imshow(mean_cov, cmap=\"viridis\", aspect=\"equal\")\n",
    "    ax.set_title(f\"Cluster {cluster_idx}\\nMean Cov\", fontsize=10, fontweight=\"bold\")\n",
    "    ax.set_xticks([0, 1, 2])\n",
    "    ax.set_yticks([0, 1, 2])\n",
    "    ax.set_xticklabels([\"HH\", \"HV\", \"VV\"], fontsize=8)\n",
    "    ax.set_yticklabels([\"HH\", \"HV\", \"VV\"], fontsize=8)\n",
    "    plt.colorbar(im, ax=ax, fraction=0.046)\n",
    "\n",
    "    # Eigenvalue distribution\n",
    "    ax = axes[1, cluster_idx]\n",
    "    eigenvalues = np.array([np.linalg.eigvalsh(c) for c in cluster_covs])\n",
    "    colors = [\"#e74c3c\", \"#3498db\", \"#2ecc71\"]\n",
    "    for eig_idx in range(3):\n",
    "        ax.hist(\n",
    "            eigenvalues[:, eig_idx],\n",
    "            bins=30,\n",
    "            alpha=0.6,\n",
    "            color=colors[eig_idx],\n",
    "            label=f\"Î»{eig_idx+1}\",\n",
    "        )\n",
    "    ax.set_xlabel(\"Eigenvalue\", fontsize=9)\n",
    "    ax.set_ylabel(\"Count\", fontsize=9)\n",
    "    ax.set_title(\"Eigenvalues\", fontsize=10)\n",
    "    if cluster_idx == n_clusters - 1:\n",
    "        ax.legend(fontsize=7)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle(\"Cluster Analysis: Covariance Structure\", fontsize=14, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting for Classification\n\nWe split the data into training and test sets for classification.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_classes = n_clusters\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=SEED\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification with pyRiemann Baselines\n\nWe compare SPDNet against pyRiemann classifiers:\n\n1. **MDM**: Minimum Distance to Mean\n2. **Tangent Space + Logistic Regression**\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Training Classifiers\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# MDM Classifier\n",
    "print(\"\\n[1] Training MDM classifier...\")\n",
    "clf_mdm = MDM(metric=\"riemann\")\n",
    "clf_mdm.fit(X_train, y_train)\n",
    "y_pred_mdm = clf_mdm.predict(X_test)\n",
    "acc_mdm = accuracy_score(y_test, y_pred_mdm)\n",
    "bal_acc_mdm = balanced_accuracy_score(y_test, y_pred_mdm)\n",
    "print(f\"    MDM Accuracy: {acc_mdm*100:.2f}%\")\n",
    "print(f\"    MDM Balanced Accuracy: {bal_acc_mdm*100:.2f}%\")\n",
    "\n",
    "# Tangent Space + Logistic Regression\n",
    "print(\"\\n[2] Training Tangent Space + LR classifier...\")\n",
    "clf_ts = make_pipeline(\n",
    "    TangentSpace(metric=\"riemann\"),\n",
    "    LogisticRegression(random_state=SEED, max_iter=1000),\n",
    ")\n",
    "clf_ts.fit(X_train, y_train)\n",
    "y_pred_ts = clf_ts.predict(X_test)\n",
    "acc_ts = accuracy_score(y_test, y_pred_ts)\n",
    "bal_acc_ts = balanced_accuracy_score(y_test, y_pred_ts)\n",
    "print(f\"    TS+LR Accuracy: {acc_ts*100:.2f}%\")\n",
    "print(f\"    TS+LR Balanced Accuracy: {bal_acc_ts*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPDNet for Radar Classification\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n[3] Training SPDNet...\")\n",
    "model = SPDNet(\n",
    "    input_type=\"cov\",\n",
    "    n_chans=3,\n",
    "    n_outputs=n_classes,\n",
    "    subspacedim=3,\n",
    "    threshold=1e-4,\n",
    ")\n",
    "\n",
    "print(\"\\nSPDNet Architecture:\")\n",
    "print(model)\n",
    "\n",
    "clf_spd = EEGClassifier(\n",
    "    module=model,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    optimizer__lr=1e-2,\n",
    "    optimizer__weight_decay=1e-4,\n",
    "    train_split=ValidSplit(0.1, stratified=True, random_state=SEED),\n",
    "    batch_size=64,\n",
    "    max_epochs=20,  # Reduced from 100 for faster documentation build\n",
    "    callbacks=[\n",
    "        (\n",
    "            \"train_acc\",\n",
    "            EpochScoring(\n",
    "                \"accuracy\", lower_is_better=False, on_train=True, name=\"train_acc\"\n",
    "            ),\n",
    "        ),\n",
    "        EarlyStopping(monitor=\"valid_loss\", patience=15),\n",
    "    ],\n",
    "    device=device,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "clf_spd.fit(X_train, y_train)\n",
    "\n",
    "y_pred_spd = clf_spd.predict(X_test)\n",
    "acc_spd = accuracy_score(y_test, y_pred_spd)\n",
    "bal_acc_spd = balanced_accuracy_score(y_test, y_pred_spd)\n",
    "print(f\"\\nSPDNet Accuracy: {acc_spd*100:.2f}%\")\n",
    "print(f\"SPDNet Balanced Accuracy: {bal_acc_spd*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Maps\n\nWe create classification maps by predicting the class for each pixel\nand displaying as an image.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Generating Classification Maps\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Predict for all pixels\n",
    "y_pred_all_mdm = clf_mdm.predict(X)\n",
    "y_pred_all_ts = clf_ts.predict(X)\n",
    "y_pred_all_spd = clf_spd.predict(X)\n",
    "\n",
    "# Reshape to images\n",
    "map_mdm = y_pred_all_mdm.reshape(h_ds, w_ds)\n",
    "map_ts = y_pred_all_ts.reshape(h_ds, w_ds)\n",
    "map_spd = y_pred_all_spd.reshape(h_ds, w_ds)\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Top row: Classification maps\n",
    "for ax, (name, pred_map, acc) in zip(\n",
    "    axes[0],\n",
    "    [\n",
    "        (\"MDM\", map_mdm, acc_mdm),\n",
    "        (\"TS + LogReg\", map_ts, acc_ts),\n",
    "        (\"SPDNet\", map_spd, acc_spd),\n",
    "    ],\n",
    "):\n",
    "    im = ax.imshow(pred_map, cmap=\"tab10\", aspect=\"auto\")\n",
    "    ax.set_title(f\"{name}\\nAccuracy: {acc*100:.1f}%\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_xlabel(\"Range\")\n",
    "    ax.set_ylabel(\"Azimuth\")\n",
    "    plt.colorbar(im, ax=ax, label=\"Class\")\n",
    "\n",
    "# Bottom row: Overlays on Pauli RGB\n",
    "for ax, (name, pred_map) in zip(\n",
    "    axes[1],\n",
    "    [(\"MDM\", map_mdm), (\"TS + LogReg\", map_ts), (\"SPDNet\", map_spd)],\n",
    "):\n",
    "    ax.imshow(pauli_rgb_ds, aspect=\"auto\")\n",
    "    ax.contour(\n",
    "        pred_map, levels=n_clusters - 1, colors=\"yellow\", linewidths=0.5, alpha=0.8\n",
    "    )\n",
    "    ax.set_title(f\"{name} Boundaries on Pauli RGB\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_xlabel(\"Range\")\n",
    "    ax.set_ylabel(\"Azimuth\")\n",
    "\n",
    "plt.suptitle(\"Classification Results Comparison\", fontsize=14, fontweight=\"bold\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"MDM\": {\"accuracy\": acc_mdm, \"balanced_accuracy\": bal_acc_mdm},\n",
    "    \"TS + LogReg\": {\"accuracy\": acc_ts, \"balanced_accuracy\": bal_acc_ts},\n",
    "    \"SPDNet\": {\"accuracy\": acc_spd, \"balanced_accuracy\": bal_acc_spd},\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Results Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n{'Method':<20} {'Accuracy':<15} {'Balanced Acc':<15}\")\n",
    "print(\"-\" * 50)\n",
    "for method, metrics in results.items():\n",
    "    print(\n",
    "        f\"{method:<20} {metrics['accuracy']*100:>6.2f}%        {metrics['balanced_accuracy']*100:>6.2f}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Visualization\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Accuracy comparison\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "methods = list(results.keys())\n",
    "accuracies = [results[m][\"accuracy\"] for m in methods]\n",
    "bal_accuracies = [results[m][\"balanced_accuracy\"] for m in methods]\n",
    "\n",
    "x = np.arange(len(methods))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(\n",
    "    x - width / 2,\n",
    "    accuracies,\n",
    "    width,\n",
    "    label=\"Accuracy\",\n",
    "    color=\"#3498db\",\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "bars2 = ax1.bar(\n",
    "    x + width / 2,\n",
    "    bal_accuracies,\n",
    "    width,\n",
    "    label=\"Balanced Acc\",\n",
    "    color=\"#2ecc71\",\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "\n",
    "ax1.set_xlabel(\"Method\", fontsize=12)\n",
    "ax1.set_ylabel(\"Score\", fontsize=12)\n",
    "ax1.set_title(\"Classification Performance\", fontsize=14, fontweight=\"bold\")\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(methods)\n",
    "ax1.set_ylim([0, 1.1])\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "for bar in bars1 + bars2:\n",
    "    ax1.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + 0.02,\n",
    "        f\"{bar.get_height():.2%}\",\n",
    "        ha=\"center\",\n",
    "        fontsize=9,\n",
    "    )\n",
    "\n",
    "# Training history\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "history = clf_spd.history\n",
    "epochs = range(1, len(history) + 1)\n",
    "ax2.plot(epochs, history[:, \"train_loss\"], \"b-\", label=\"Train Loss\", linewidth=2)\n",
    "ax2.plot(epochs, history[:, \"valid_loss\"], \"r--\", label=\"Valid Loss\", linewidth=2)\n",
    "ax2.set_xlabel(\"Epoch\", fontsize=12)\n",
    "ax2.set_ylabel(\"Loss\", fontsize=12)\n",
    "ax2.set_title(\"SPDNet Training History\", fontsize=14, fontweight=\"bold\")\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Confusion matrices\n",
    "cluster_labels = [f\"C{i}\" for i in range(n_classes)]\n",
    "\n",
    "ax3 = fig.add_subplot(2, 3, 4)\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_pred_mdm,\n",
    "    ax=ax3,\n",
    "    display_labels=cluster_labels,\n",
    "    cmap=\"Blues\",\n",
    "    colorbar=False,\n",
    ")\n",
    "ax3.set_title(\"MDM\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "ax4 = fig.add_subplot(2, 3, 5)\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_pred_ts,\n",
    "    ax=ax4,\n",
    "    display_labels=cluster_labels,\n",
    "    cmap=\"Blues\",\n",
    "    colorbar=False,\n",
    ")\n",
    "ax4.set_title(\"TS + LogReg\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "ax5 = fig.add_subplot(2, 3, 6)\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test,\n",
    "    y_pred_spd,\n",
    "    ax=ax5,\n",
    "    display_labels=cluster_labels,\n",
    "    cmap=\"Blues\",\n",
    "    colorbar=False,\n",
    ")\n",
    "ax5.set_title(\"SPDNet\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "plt.suptitle(\n",
    "    \"UAVSAR Classification with SPD Methods\", fontsize=16, fontweight=\"bold\", y=1.02\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n\nIn this tutorial, we demonstrated:\n\n1. **Real PolSAR data**: Loaded NASA UAVSAR data from Zenodo\n\n2. **SAR visualization**: Displayed radar intensity and Pauli RGB\n\n3. **Covariance estimation**: Computed 3x3 SPD matrices from\n   polarimetric scattering vectors\n\n4. **Riemannian clustering**: Generated pseudo-labels using K-Means\n   with the Riemannian metric\n\n5. **Classification comparison**: Compared MDM, Tangent Space + LR,\n   and SPDNet on real radar data\n\n6. **Classification maps**: Visualized spatial prediction results\n\n**Key takeaways:**\n\n- PolSAR covariance matrices are naturally SPD\n- Riemannian geometry captures meaningful terrain differences\n- SPDNet learns features directly on the SPD manifold\n- Classification maps reveal spatial patterns in the radar image\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.close(\"all\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
