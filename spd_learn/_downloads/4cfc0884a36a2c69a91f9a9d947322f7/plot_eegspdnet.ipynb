{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SPD Learn Example\n",
    "# ==================\n",
    "#\n",
    "# First, install the required packages:\n",
    "\n",
    "!uv pip install -q spd_learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n\n# EEG Classification with EEGSPDNet\n\nThis tutorial demonstrates how to use EEGSPDNet for motor imagery\nEEG classification. EEGSPDNet combines channel-specific convolution\nwith SPD matrix learning for robust EEG decoding.\n   :depth: 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n\nEEGSPDNet :cite:p:`wilson2025deep` is a deep Riemannian network designed\nspecifically for\nEEG decoding. It extends the SPDNet architecture with:\n\n- **Channel-specific convolution**: Learns temporal filters independently\n  for each EEG channel using grouped convolutions\n- **Covariance pooling**: Computes SPD covariance matrices from the\n  filtered signals\n- **Scalable BiMap layers**: Progressively reduces dimensionality on\n  the SPD manifold\n- **SPD Dropout**: Structured dropout that maintains positive definiteness\n\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from braindecode import EEGClassifier\n",
    "from moabb.datasets import BNCI2014_001\n",
    "from moabb.paradigms import MotorImagery\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skorch.callbacks import EpochScoring, GradientNormClipping\n",
    "from skorch.dataset import ValidSplit\n",
    "\n",
    "from spd_learn.models import EEGSPDNet\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n\nWe use the BCI Competition IV Dataset 2a for motor imagery classification.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = BNCI2014_001()\n",
    "paradigm = MotorImagery(n_classes=4)\n",
    "\n",
    "print(f\"Dataset: {dataset.code}\")\n",
    "print(f\"Number of subjects: {len(dataset.subject_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding EEGSPDNet Architecture\n\nEEGSPDNet processes EEG in the following stages:\n\n1. **Channel-specific Conv1d**: Each channel gets its own set of filters\n\n   .. math::\n\n      X_{conv} = \\text{GroupedConv1d}(X), \\quad X \\in \\mathbb{R}^{C \\times T}\n\n   Output shape: ``(n_chans * n_filters, time - filter_length + 1)``\n\n2. **Covariance Pooling**: Compute SPD covariance matrix\n\n   .. math::\n\n      \\Sigma = \\frac{1}{T-1} X_{conv} X_{conv}^T\n\n3. **BiMap + ReEig blocks**: Learn spatial filters while preserving SPD\n\n   .. math::\n\n      Y = W^T \\Sigma W, \\quad Y = U \\max(\\Lambda, \\epsilon) U^T\n\n4. **LogEig**: Project to tangent space for classification\n\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the EEGSPDNet Model\n\nKey parameters:\n\n- ``n_filters``: Number of temporal filters per channel\n- ``bimap_sizes``: Tuple (k, n_layers) defining scaling factor and depth\n- ``filter_time_length``: Length of temporal convolution kernel\n- ``spd_drop_prob``: Dropout probability for SPD dropout layers\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_chans = 22\n",
    "n_outputs = 4\n",
    "\n",
    "# Create EEGSPDNet model\n",
    "model = EEGSPDNet(\n",
    "    n_chans=n_chans,\n",
    "    n_outputs=n_outputs,\n",
    "    n_filters=4,  # 4 filters per channel → 88 total\n",
    "    bimap_sizes=(2, 2),  # Scale by 2x, 2 BiMap layers: 88→44→22\n",
    "    filter_time_length=25,  # 100ms filter at 250Hz\n",
    "    spd_drop_prob=0.0,  # No SPD dropout (can cause instability)\n",
    "    spd_drop_scaling=True,  # Scale remaining channels\n",
    "    final_layer_drop_prob=0.5,  # 50% dropout before classifier\n",
    ")\n",
    "\n",
    "print(\"EEGSPDNet Architecture:\")\n",
    "print(model)\n",
    "\n",
    "# Show BiMap layer dimensions\n",
    "print(\"\\nBiMap Layer Dimensions:\")\n",
    "print(\"Input: 88 x 88 (22 channels x 4 filters)\")\n",
    "print(\"→ BiMap0: 88 → 44\")\n",
    "print(\"→ BiMap1: 44 → 22\")\n",
    "print(\"→ LogEig: 22 x 22 → 253 (upper triangular)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Classifier\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "max_epochs = 100\n",
    "learning_rate = 1e-4  # Low learning rate for stable SPD learning\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "# Note: SPD networks benefit from gradient clipping to prevent\n",
    "# divergence during training on the Riemannian manifold.\n",
    "clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    optimizer__lr=learning_rate,\n",
    "    train_split=ValidSplit(0.1, stratified=True, random_state=42),\n",
    "    batch_size=batch_size,\n",
    "    max_epochs=max_epochs,\n",
    "    callbacks=[\n",
    "        (\n",
    "            \"train_acc\",\n",
    "            EpochScoring(\n",
    "                \"accuracy\", lower_is_better=False, on_train=True, name=\"train_acc\"\n",
    "            ),\n",
    "        ),\n",
    "        (\"gradient_clip\", GradientNormClipping(gradient_clip_value=1.0)),\n",
    "    ],\n",
    "    device=device,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subject_id = 1\n",
    "\n",
    "# Cache configuration\n",
    "cache_config = dict(\n",
    "    save_raw=True,\n",
    "    save_epochs=True,\n",
    "    save_array=True,\n",
    "    use=True,\n",
    "    overwrite_raw=False,\n",
    "    overwrite_epochs=False,\n",
    "    overwrite_array=False,\n",
    ")\n",
    "\n",
    "# Load data\n",
    "X, labels, meta = paradigm.get_data(\n",
    "    dataset=dataset, subjects=[subject_id], cache_config=cache_config\n",
    ")\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)\n",
    "\n",
    "print(f\"\\nData shape: {X.shape}\")\n",
    "print(f\"Classes: {le.classes_}\")\n",
    "\n",
    "# Split by session\n",
    "train_idx = meta.query(\"session == '0train'\").index.to_numpy()\n",
    "test_idx = meta.query(\"session == '1test'\").index.to_numpy()\n",
    "\n",
    "print(f\"Training samples: {len(train_idx)}\")\n",
    "print(f\"Test samples: {len(test_idx)}\")\n",
    "\n",
    "# Train\n",
    "clf.fit(X[train_idx], y[train_idx])\n",
    "\n",
    "# Evaluate\n",
    "y_pred_train = clf.predict(X[train_idx])\n",
    "y_pred_test = clf.predict(X[test_idx])\n",
    "\n",
    "train_acc = accuracy_score(y[train_idx], y_pred_train)\n",
    "test_acc = accuracy_score(y[test_idx], y_pred_test)\n",
    "test_bal_acc = balanced_accuracy_score(y[test_idx], y_pred_test)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Results for Subject {subject_id}\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Train Accuracy:    {train_acc*100:.2f}%\")\n",
    "print(f\"Test Accuracy:     {test_acc*100:.2f}%\")\n",
    "print(f\"Test Balanced Acc: {test_bal_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Results\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "history = clf.history\n",
    "epochs = range(1, len(history) + 1)\n",
    "\n",
    "# Loss\n",
    "ax1 = axes[0]\n",
    "ax1.plot(epochs, history[:, \"train_loss\"], \"b-\", label=\"Train Loss\", linewidth=2)\n",
    "ax1.plot(epochs, history[:, \"valid_loss\"], \"r--\", label=\"Valid Loss\", linewidth=2)\n",
    "ax1.set_xlabel(\"Epoch\", fontsize=12)\n",
    "ax1.set_ylabel(\"Loss\", fontsize=12)\n",
    "ax1.set_title(\"Training and Validation Loss\", fontsize=14)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "ax2 = axes[1]\n",
    "ax2.plot(epochs, history[:, \"train_acc\"], \"b-\", label=\"Train Acc\", linewidth=2)\n",
    "ax2.plot(epochs, history[:, \"valid_acc\"], \"r--\", label=\"Valid Acc\", linewidth=2)\n",
    "ax2.set_xlabel(\"Epoch\", fontsize=12)\n",
    "ax2.set_ylabel(\"Accuracy\", fontsize=12)\n",
    "ax2.set_title(\"Training and Validation Accuracy\", fontsize=14)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim([0, 1])\n",
    "\n",
    "# Confusion Matrix\n",
    "ax3 = axes[2]\n",
    "cm = confusion_matrix(y[test_idx], y_pred_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(ax=ax3, cmap=\"Blues\", values_format=\"d\")\n",
    "ax3.set_title(f\"Test Confusion Matrix\\nAccuracy: {test_acc*100:.1f}%\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with Different Configurations\n\nLet's compare different EEGSPDNet configurations to understand\nthe impact of hyperparameters.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "configs = {\n",
    "    \"Small (k=2, depth=1)\": {\"bimap_sizes\": (2, 1), \"n_filters\": 4},\n",
    "    \"Medium (k=2, depth=2)\": {\"bimap_sizes\": (2, 2), \"n_filters\": 4},\n",
    "    \"Large (k=2, depth=3)\": {\"bimap_sizes\": (2, 3), \"n_filters\": 6},\n",
    "}\n",
    "\n",
    "print(\"\\nModel Size Comparison:\")\n",
    "print(\"-\" * 60)\n",
    "for name, config in configs.items():\n",
    "    temp_model = EEGSPDNet(n_chans=n_chans, n_outputs=n_outputs, **config)\n",
    "    n_params = sum(p.numel() for p in temp_model.parameters())\n",
    "    print(f\"{name}: {n_params:,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n\nIn this tutorial, we demonstrated how to:\n\n1. Create and configure an EEGSPDNet model\n2. Understand the architecture's channel-specific processing\n3. Train and evaluate on motor imagery data\n4. Compare different model configurations\n\nEEGSPDNet's channel-specific convolution allows it to learn\nindependent temporal features for each electrode, which is\nparticularly useful for spatially distributed brain signals.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.close(\"all\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
