{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SPD Learn Example\n",
    "# ==================\n",
    "#\n",
    "# First, install the required packages:\n",
    "\n",
    "!uv pip install -q spd_learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n\n# Learnable Wavelets with GREEN for EEG Classification\n\nThis tutorial demonstrates how to use the GREEN (Gabor Riemann EEGNet)\nmodel for EEG classification. GREEN combines learnable Gabor wavelets\nwith Riemannian geometry for biomarker exploration.\n   :depth: 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n\nGREEN :cite:p:`paillard2024green` is a lightweight architecture that learns\noptimal time-frequency\nrepresentations directly from EEG data. Unlike traditional approaches that\nuse fixed filter banks, GREEN employs parametrized Gabor wavelets with\nlearnable center frequencies and bandwidths.\n\nKey features of GREEN:\n\n- **Learnable wavelets**: Center frequencies and FWHM are optimized during training\n- **Riemannian geometry**: SPD covariance matrices with BiMap and LogEig layers\n- **Lightweight**: Efficient architecture suitable for clinical applications\n\n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n\nFirst, we import the necessary libraries.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from braindecode import EEGClassifier\n",
    "from moabb.datasets import BNCI2014_001\n",
    "from moabb.paradigms import MotorImagery\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from skorch.callbacks import EpochScoring\n",
    "from skorch.dataset import ValidSplit\n",
    "\n",
    "from spd_learn.models import Green\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n\nWe use the BCI Competition IV Dataset 2a (BNCI2014_001), which contains\nmotor imagery EEG recordings from 9 subjects.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = BNCI2014_001()\n",
    "paradigm = MotorImagery(n_classes=4)\n",
    "\n",
    "print(f\"Dataset: {dataset.code}\")\n",
    "print(f\"Subjects: {dataset.subject_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the GREEN Model\n\nGREEN processes EEG through the following stages:\n\n1. **Wavelet Convolution**: Learnable Gabor wavelets extract time-frequency features\n2. **Covariance Pooling**: Compute SPD covariance matrices\n3. **Shrinkage**: Ledoit-Wolf regularization for stable covariance estimation\n4. **BiMap Layers**: Optional spatial filtering on the SPD manifold\n5. **LogEig + BatchReNorm**: Project to tangent space with normalization\n6. **MLP Head**: Classification with dropout\n\nKey parameters:\n\n- ``n_freqs_init``: Number of wavelet center frequencies (default: 10)\n- ``kernel_width_s``: Wavelet kernel width in seconds\n- ``oct_min/oct_max``: Frequency range in octaves (relative to 1 Hz)\n- ``shrinkage_init``: Initial shrinkage coefficient (sigmoid input)\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "n_chans = 22\n",
    "n_outputs = 4\n",
    "sfreq = 250  # Sampling frequency of BNCI2014_001\n",
    "\n",
    "# Create GREEN model\n",
    "model = Green(\n",
    "    n_outputs=n_outputs,\n",
    "    n_chans=n_chans,\n",
    "    sfreq=sfreq,\n",
    "    n_freqs_init=10,  # Number of learnable wavelets\n",
    "    kernel_width_s=0.5,  # 500ms wavelet width\n",
    "    oct_min=0,  # ~1 Hz minimum\n",
    "    oct_max=5,  # ~32 Hz maximum (2^5)\n",
    "    shrinkage_init=-3.0,  # Initial shrinkage (sigmoid(-3) â‰ˆ 0.05)\n",
    "    hidden_dim=(16,),  # Hidden layer in MLP head\n",
    "    dropout=0.5,\n",
    ")\n",
    "\n",
    "print(\"\\nGREEN Model Architecture:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Classifier\n\nWe use Braindecode's EEGClassifier wrapper for scikit-learn compatibility.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "batch_size = 32\n",
    "max_epochs = 50\n",
    "learning_rate = 1e-3\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "clf = EEGClassifier(\n",
    "    model,\n",
    "    criterion=torch.nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    optimizer__lr=learning_rate,\n",
    "    optimizer__weight_decay=1e-4,\n",
    "    train_split=ValidSplit(0.1, stratified=True, random_state=42),\n",
    "    batch_size=batch_size,\n",
    "    max_epochs=max_epochs,\n",
    "    callbacks=[\n",
    "        (\n",
    "            \"train_acc\",\n",
    "            EpochScoring(\n",
    "                \"accuracy\", lower_is_better=False, on_train=True, name=\"train_acc\"\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"bal_acc\",\n",
    "            EpochScoring(\n",
    "                \"balanced_accuracy\",\n",
    "                lower_is_better=False,\n",
    "                on_train=False,\n",
    "                name=\"bal_acc\",\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    device=device,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation\n\nWe train on a single subject for demonstration.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subject_id = 1\n",
    "\n",
    "# Cache configuration\n",
    "cache_config = dict(\n",
    "    save_raw=True,\n",
    "    save_epochs=True,\n",
    "    save_array=True,\n",
    "    use=True,\n",
    "    overwrite_raw=False,\n",
    "    overwrite_epochs=False,\n",
    "    overwrite_array=False,\n",
    ")\n",
    "\n",
    "# Load data\n",
    "X, labels, meta = paradigm.get_data(\n",
    "    dataset=dataset, subjects=[subject_id], cache_config=cache_config\n",
    ")\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)\n",
    "\n",
    "print(f\"\\nData shape: {X.shape}\")\n",
    "print(f\"Classes: {le.classes_}\")\n",
    "\n",
    "# Split by session\n",
    "train_idx = meta.query(\"session == '0train'\").index.to_numpy()\n",
    "test_idx = meta.query(\"session == '1test'\").index.to_numpy()\n",
    "\n",
    "print(f\"Training samples: {len(train_idx)}\")\n",
    "print(f\"Test samples: {len(test_idx)}\")\n",
    "\n",
    "# Train\n",
    "clf.fit(X[train_idx], y[train_idx])\n",
    "\n",
    "# Evaluate\n",
    "y_pred_train = clf.predict(X[train_idx])\n",
    "y_pred_test = clf.predict(X[test_idx])\n",
    "\n",
    "train_acc = accuracy_score(y[train_idx], y_pred_train)\n",
    "test_acc = accuracy_score(y[test_idx], y_pred_test)\n",
    "test_bal_acc = balanced_accuracy_score(y[test_idx], y_pred_test)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Results for Subject {subject_id}\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Train Accuracy:    {train_acc*100:.2f}%\")\n",
    "print(f\"Test Accuracy:     {test_acc*100:.2f}%\")\n",
    "print(f\"Test Balanced Acc: {test_bal_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Learned Wavelets\n\nOne advantage of GREEN is that we can inspect the learned wavelet\nparameters to understand which frequencies are most discriminative.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Extract learned wavelet parameters\n",
    "wavelet_conv = model.conv_layers[0]\n",
    "foi_learned = wavelet_conv.foi.detach().cpu().numpy()  # Center frequencies (octaves)\n",
    "fwhm_learned = wavelet_conv.fwhm.detach().cpu().numpy()  # Bandwidth (octaves)\n",
    "\n",
    "# Convert from octaves to Hz\n",
    "foi_hz = 2**foi_learned\n",
    "bandwidth_hz = 2 ** np.abs(fwhm_learned)\n",
    "\n",
    "print(\"\\nLearned Wavelet Parameters:\")\n",
    "print(\"-\" * 40)\n",
    "for i, (f, bw) in enumerate(zip(foi_hz, bandwidth_hz)):\n",
    "    print(f\"Wavelet {i+1}: Center = {f:.1f} Hz, Bandwidth = {bw:.1f} Hz\")\n",
    "\n",
    "# Plot wavelet frequencies\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "# Sort by center frequency for visualization\n",
    "sort_idx = np.argsort(foi_hz)\n",
    "foi_sorted = foi_hz[sort_idx]\n",
    "bw_sorted = bandwidth_hz[sort_idx]\n",
    "\n",
    "x_pos = np.arange(len(foi_sorted))\n",
    "ax.bar(x_pos, foi_sorted, yerr=bw_sorted / 2, capsize=5, color=\"steelblue\", alpha=0.7)\n",
    "ax.set_xlabel(\"Wavelet Index (sorted by frequency)\", fontsize=12)\n",
    "ax.set_ylabel(\"Center Frequency (Hz)\", fontsize=12)\n",
    "ax.set_title(\"Learned Gabor Wavelet Center Frequencies\", fontsize=14)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "# Add frequency band annotations\n",
    "ax.axhline(y=8, color=\"green\", linestyle=\"--\", alpha=0.5, label=\"Mu band (8-12 Hz)\")\n",
    "ax.axhline(y=12, color=\"green\", linestyle=\"--\", alpha=0.5)\n",
    "ax.axhline(\n",
    "    y=13, color=\"orange\", linestyle=\"--\", alpha=0.5, label=\"Beta band (13-30 Hz)\"\n",
    ")\n",
    "ax.axhline(y=30, color=\"orange\", linestyle=\"--\", alpha=0.5)\n",
    "ax.legend(loc=\"upper left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training History\n\nLet's visualize the training progress.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "history = clf.history\n",
    "epochs = range(1, len(history) + 1)\n",
    "\n",
    "# Loss\n",
    "ax1 = axes[0]\n",
    "ax1.plot(epochs, history[:, \"train_loss\"], \"b-\", label=\"Train Loss\", linewidth=2)\n",
    "ax1.plot(epochs, history[:, \"valid_loss\"], \"r--\", label=\"Valid Loss\", linewidth=2)\n",
    "ax1.set_xlabel(\"Epoch\", fontsize=12)\n",
    "ax1.set_ylabel(\"Loss\", fontsize=12)\n",
    "ax1.set_title(\"Training and Validation Loss\", fontsize=14)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "ax2 = axes[1]\n",
    "ax2.plot(epochs, history[:, \"train_acc\"], \"b-\", label=\"Train Acc\", linewidth=2)\n",
    "ax2.plot(epochs, history[:, \"bal_acc\"], \"r--\", label=\"Valid Balanced Acc\", linewidth=2)\n",
    "ax2.set_xlabel(\"Epoch\", fontsize=12)\n",
    "ax2.set_ylabel(\"Accuracy\", fontsize=12)\n",
    "ax2.set_title(\"Training and Validation Accuracy\", fontsize=14)\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n\nIn this tutorial, we demonstrated how to:\n\n1. Create a GREEN model with learnable Gabor wavelets\n2. Train and evaluate on motor imagery EEG data\n3. Visualize the learned wavelet parameters\n\nGREEN's learnable wavelets allow the model to discover optimal\ntime-frequency representations for the classification task, often\nfocusing on the mu (8-12 Hz) and beta (13-30 Hz) rhythms known\nto be modulated during motor imagery.\n\n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.close(\"all\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
